### Sum√°rio
+ [Instala√ß√£o e configura√ß√£o do Java JDK 8](#Java)
+ [Instala√ß√£o e configura√ß√£o do Apache Hadoop](#Hadoop)
    + [Configura√ß√£o do Hadoop](#ConfiguracaoHadoop)
    + [Inicializa√ß√£o do Hadoop](#InicializacaoHadoop)
+ [Instala√ß√£o e configura√ß√£o do Apache Kafka](#Kafka)
+ [Instala√ß√£o e configura√ß√£o do Apache Nifi](#Nifi)
+ [Instala√ß√£o e configura√ß√£o do Apache Spark](#Spark)
    + [Configurando o Spark em Multinode Cluster](#Cluster)
+ [Instala√ß√£o e configura√ß√£o do Apache Hive](#Hive)
    + [Configura√ß√£o do Metastore com Banco de Dados Oracle](#Oracle)
    + [Configura√ß√£o do Metastore com Banco de Dados MySQL](#MySQL)
    + [Testando o Hive](#HiveTest)

<a name = "Java"></a>

### Instala√ß√£o e configura√ß√£o do Java JDK 8

Maior parte das aplica√ß√µes da Apache roda sobre o Java, para isso devemos instalar o Java JDK, estarei utilizando a vers√£o 8 porque √© compat√≠vel com maior parte dos componentes, por mais que a vers√£o do Hadoop atual suporte o Java 11.
 
> **üí°**: Certifique-se de que todas as m√°quinas est√£o ligadas.

<b>Download do Java 8</b>

Para isso √© necess√°rio baixar o Java JDK 8 atrav√©s do seguinte link:

[https://www.oracle.com/br/java/technologies/javase/javase8-archive-downloads.html](https://www.oracle.com/br/java/technologies/javase/javase8-archive-downloads.html)

Estarei selecionando a vers√£o de Linux x64 compactada.

Baixe a op√ß√£o na sua m√°quina local:

- jdk-8u202-linux-x64.tar.gz

> **üí°**: Estarei selecionando essa op√ß√£o, mas n√£o √© obrigat√≥rio, baixe a compat√≠vel com a sua m√°quina.

![Untitled](/Imagens/Untitled%2052.png)

Ser√° solicitado o login, caso n√£o tenha, fa√ßa um cadastro no site da Oracle.

[https://profile.oracle.com/myprofile/account/create-account.jspx](https://profile.oracle.com/myprofile/account/create-account.jspx)

![Untitled](/Imagens/Untitled%2053.png)

Ap√≥s o login o Download ser√° iniciado automaticamente.

<br>

<b>Copiando o Java para as m√°quinas</b>

Depois de baixar, faremos a c√≥pia desse arquivo.

Abra o terminal da sua m√°quina local, onde foi baixado o Java e execute o comando:

```bash
scp /caminho/jdk-8u202-linux-x64.tar.gz root@ipdonamenode:/opt
```

![Untitled](/Imagens/Untitled%2054.png)

Fa√ßa a c√≥pia do Java para os Datanodes tamb√©m

```bash
scp /caminho/jdk-8u202-linux-x64.tar.gz root@ipdodatanode:/opt
```

![Untitled](/Imagens/Untitled%2055.png)

Ap√≥s a execu√ß√£o, verifique se a c√≥pia realmente foi feita. Acesse o diret√≥rio `/opt/` das m√°quinas e execute o comando `ls -la` para verificar se o arquivo foi realmente copiado

![Untitled](/Imagens/Untitled%2056.png)

Ap√≥s verificar estamos preparados para instalar o Java.

> **üí°**: √â necess√°rio realizar todos passos seguintes em todas as m√°quinas.

### Instala√ß√£o do Java 8 

Para a instala√ß√£o, o primeiro passo √© extrair o conte√∫do do arquivo jdk-8u202-linux-x64.tar.gz,

para isso utilizaremos o comando, respons√°vel por extrair os arquivos:

```bash
sudo tar xzf jdk-8u202-linux-x64.tar.gz
```

Verificando se foi extra√≠do corretamente:

```bash
ls -la
```

![Untitled](/Imagens/Untitled%2057.png)

Agora irei apagar o arquivo compactado, renomear o diret√≥rio criado para JDK e alterar o dono e grupo, seguindo uma boa pr√°tica de padroniza√ß√£o.

```bash
sudo rm -rf jdk-8u202-linux-x64.tar.gz
sudo mv jdk1.8.0_202/ /opt/jdk
ls -la
sudo chown -R root:root jdk/
```

![Untitled](/Imagens/Untitled%2058.png)

Para dar continuidade a instala√ß√£o, precisa configurar as vari√°veis de ambiente, para isso edite o arquivo `.bash_profile`, localizado no `~/`

Insira as seguintes configura√ß√µes no arquivo, indicando o caminho do Java:

```bash
export JAVA_HOME=/opt/jdk
export JRE_HOME=/opt/jdk/jre
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
```

![Untitled](/Imagens/Untitled%2059.png)

Para atualizar o arquivo de vari√°veis de ambiente rode o comando:

```bash
source .bash_profile
```

Para verificar se tudo est√° configurado corretamente, rode o comando 

```bash
java -version
```

![Caso apare√ßa a vers√£o, significa que tudo est√° corretamente configurado.](/Imagens/Untitled%2060.png)

Caso apare√ßa a vers√£o, significa que tudo est√° corretamente configurado.

Agora √© poss√≠vel a instala√ß√£o do Hadoop.

<br>

<a name = "Componentes"></a>
## Instalando e configurando os componentes

<br>
<a name = "Hadoop"></a>

### Instala√ß√£o e configura√ß√£o do Apache Hadoop

> **Nota**: Para a instala√ß√£o do Hadoop, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

Primeiro passo √© fazer o Download do arquivo bin√°rio do Hadoop 3.3.4:

[https://hadoop.apache.org/releases.html](https://hadoop.apache.org/releases.html)

![Untitled](/Imagens/Untitled%2061.png)

Copie o link de Download

[https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz](https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz)

![Untitled](/Imagens/Untitled%2062.png)

Abra o terminal do Namenode, v√° ao diret√≥rio `/opt/` e insira o comando `wget` com o link do Hadoop:

> **üí°**: S√≥ ser√° poss√≠vel a execu√ß√£o do comando wget, caso voc√™ tenha ele instalado.

```bash
sudo wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz
```

![Untitled](/Imagens/Untitled%2063.png)

Verificando, extraindo, removendo o arquivo compactado e alterando o nome do diret√≥rio.

```bash
ls -la
sudo tar xzf hadoop-3.3.4.tar.gz
sudo rm -rf hadoop-3.3.4.tar.gz
sudo mv hadoop-3.3.4/ /opt/hadoop
```

![Untitled](/Imagens/Untitled%2064.png)

Adotando novamente outro padr√£o, estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake hadoop/
```

![Untitled](/Imagens/Untitled%2065.png)

Agora irei configurar as vari√°veis de ambiente do meu usu√°rio datalake inserindo as seguintes configura√ß√µes:

```bash
export HADOOP_HOME=/opt/hadoop
export HADOOP_CONF_DIR="${HADOOP_HOME}/etc/hadoop"
export PATH=$PATH:$HADOOP_HOME/bin
```

![Untitled](/Imagens/Untitled%2066.png)

Agora podemos testar a vers√£o do Hadoop, caso as vari√°veis de ambiente tenham sido corretamente configuradas.

```bash
hadoop version
```

![Untitled](/Imagens/Untitled%2067.png)

<br>

<a name = "ConfiguracaoHadoop"></a>
<b> Configura√ß√£o do Hadoop</b>

Ap√≥s a instala√ß√£o e configura√ß√£o das vari√°veis de ambiente, precisamos configurar o Hadoop, para isso √© necess√°rio entrar no diret√≥rio: `/opt/hadoop/etc/hadoop`

Come√ßarei configurando o arquivo `hadoop-env.sh`, insira ou habilite as seguintes linhas no arquivo:

```bash
export JAVA_HOME=/opt/jdk
export HADOOP_HOME=/opt/hadoop
export HADOOP_CONF_DIR="${HADOOP_HOME}/etc/hadoop"
export PATH="${PATH}:${HADOOP_HOME}/bin"
export HADOOP_SSH_OPTS="-i ~/.ssh/id_rsa"
```

![Untitled](/Imagens/Untitled%2068.png)

Configurando o arquivo `core-site.xml`

Apague as tags `configuration`.

> **üí°**: Muito cuidado apagando este tipo de arquivo para n√£o apagar as indenta√ß√µes.

![Untitled](/Imagens/Untitled%2069.png)

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://namenode:19000</value>
    </property>
</configuration>
```

![Untitled](/Imagens/Untitled%2070.png)

Configurando o `hdfs-site.xml`

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/hadoop/dfs/namespace_logs</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop/dfs/data</value>
    </property>
</configuration>
```

![Untitled](/Imagens/Untitled%2071.png)

Configurando o `mapred-site.xml`

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>mapreduce.job.user.name</name>
        <value>hadoop</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>namenode:8032</value>
    </property>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
</configuration>
```

![Untitled](/Imagens/Untitled%2072.png)

Configurando o `yarn-site.xml`

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>namenode</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>1536</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>1536</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>128</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>yarn.server.resourcemanager.application.expiry.interval</name>
        <value>60000</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>-1</value>
    </property>
    <property>
        <name>yarn.application.classpath</name>
        <value>$HADOOP_CONF_DIR,${HADOOP_COMMON_HOME}/share/hadoop/common/*,${HADOOP_COMMON_HOME}/share/hadoop/common/lib/*,${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*,${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*,${HADOOP_MAPRED_HOME}/share/hadoop/mapreduce/*,${HADOOP_MAPRED_HOME}/share/hadoop/mapreduce/lib/*,${HADOOP_YARN_HOME}/share/hadoop/yarn/*,${HADOOP_YARN_HOME}/share/hadoop/yarn/lib/*</value>`

    </property>
</configuration>
```

![Untitled](/Imagens/Untitled%2073.png)

Por √∫ltimo a configura√ß√£o do arquivo `workers`, nele ser√£o inseridos os Datanodes que far√£o comunica√ß√£o com o Namenode. Insira o nome dos Datanodes.

> **üí°**: Esses nomes s√£o das m√°quinas configuradas no arquivo ==hosts==.

![Untitled](/Imagens/Untitled%2074.png)

Configura√ß√£o finalizada, mas antes de rodar o Hadoop, precisamos criar os diret√≥rios onde ser√£o salvo os logs e registros do HDFS, para isso executei os comandos:

```bash
mkdir /opt/hadoop/dfs
mkdir /opt/hadoop/dfs/data
mkdir /opt/hadoop/dfs/namespace_logs
```

Ap√≥s a instala√ß√£o do Hadoop,  tamb√©m √© necess√°rio realizar esse processo nos Datanodes, para n√£o precisar repetir todo processo novamente.

Farei a c√≥pia do diret√≥rio do Hadoop no Namenode, para os Datanodes.

Para fazer a copiar do Hadoop para os Datanodes, √© essencial que seja criado a pasta dele antes de receber a c√≥pia do diret√≥rio.

> **üí°**: Fa√ßa isso para todos os Datanodes.

```bash
sudo mkdir /opt/hadoop 
```

![Untitled](/Imagens/Untitled%2075.png)

Caso esteja usando o padr√£o que estou seguindo, √© importante alterar o dono e o grupo do diret√≥rio para datalake, igualmente feito no Namenode.

```bash
sudo chown -R datalake:datalake hadoop/
```

![Untitled](/Imagens/Untitled%2076.png)

Agora posso fazer a c√≥pia do diret√≥rio Hadoop configurado no Namenode para os Datanodes, utilizando a chave de seguran√ßa SSH.

```bash
scp -rv -i "~/.ssh/id_rsa" /opt/hadoop datalake@datanode1:/opt
scp -rv -i "~/.ssh/id_rsa" /opt/hadoop datalake@datanode2:/opt
```

Ao terminar a c√≥pia aparecer√° essa tela:

![Untitled](/Imagens/Untitled%2077.png)

Acesse a pasta `/opt/hadoop` nos Datanodes e execute o comando `ls` para verificar se os arquivos chegaram corretamente.

![Untitled](/Imagens/Untitled%2078.png)

Fim da instala√ß√£o do Hadoop, agora, utilizando o Namenode formatei o HDFS

```bash
hadoop namenode -format
```

![Untitled](/Imagens/Untitled%2079.png)

<br>

<a name = "InicializacaoHadoop"></a>
<b>Inicializa√ß√£o do Hadoop</b>

Ap√≥s a formata√ß√£o do HDFS, iniciarei todos os servi√ßos do Hadoop.

```bash
$HADOOP_HOME/sbin/start-all.sh
```

![Untitled](/Imagens/Untitled%2080.png)

Verificando atrav√©s do terminal se os servi√ßos foram iniciados corretamente nas m√°quinas.

```bash
jps
```

![Untitled](/Imagens/Untitled%2081.png)

![Untitled](/Imagens/Untitled%2082.png)

![Untitled](/Imagens/Untitled%2083.png)

Importando um arquivo teste e listando ele no HDFS

```bash
hdfs dfs -put alexandre.txt /
hdfs dfs -ls /
```

![Untitled](/Imagens/Untitled%2084.png)

Acessando a interface web do Hadoop utilizando meu IP do Namenode com a porta `9870`

```bash
http://192.168.1.16:9870/
```

![Untitled](/Imagens/Untitled%2085.png)

Verificando o funcionamento dos Datanodes

```bash
http://192.168.1.16:9870/dfshealth.html#tab-datanode
```

![Untitled](/Imagens/Untitled%2086.png)

Verificando visualmente os arquivos dentro do HDFS

```bash
http://192.168.1.16:9870/explorer.html#/
```

![Untitled](/Imagens/Untitled%2087.png)

Verifica√ß√£o do funcionamento do Yarn

```bash
http://192.168.1.16:8088/cluster
```

![Untitled](/Imagens/Untitled%2088.png)

Tudo funcionando corretamente, irei desligar o Hadoop.

```bash
$HADOOP_HOME/sbin/stop-all.sh
```

![Untitled](/Imagens/Untitled%2089.png)

<br>

<a name = "Kafka"></a>
### Instala√ß√£o e configura√ß√£o do Apache Kafka

> **üí°**: Para a instala√ß√£o do Kafka, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

Primeiro passo √© fazer o Download do arquivo bin√°rio do Kafka:

[https://kafka.apache.org/downloads](https://kafka.apache.org/downloads)

![Untitled](/Imagens/Untitled%2090.png)

Copie o link de download do bin√°rio:

[https://downloads.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz](https://downloads.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz)

Conectado ao Namenode, no diret√≥rio `/opt/`, fa√ßa o Download do bin√°rio

```bash
sudo wget https://downloads.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz
```

![Untitled](/Imagens/Untitled%2091.png)

Ap√≥s finalizar o Download, √© necess√°rio descompact√°-lo, remover o arquivo compactado, alterar o nome e dono do arquivo.

```bash
sudo tar xzf kafka_2.13-3.3.1.tgz
sudo rm -rf kafka_2.13-3.3.1.tgz
sudo mv kafka_2.13-3.3.1/ /opt/kafka
```

![Untitled](/Imagens/Untitled%2092.png)

Adotando novamente outro padr√£o, estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake kafka/
```

![Untitled](/Imagens/Untitled%2093.png)

Configurando as vari√°veis de ambiente no arquivo `~/.bash_profile`

```bash
export KAFKA_HOME=/opt/kafka 
export PATH=$PATH:$KAFKA_HOME/bin
```

![Untitled](/Imagens/Untitled%2094.png)

No diret√≥rio `/opt/kafka/config` fa√ßa a c√≥pia do arquivo `server.properties`

```bash
cp server.properties server1.properties
cp server.properties server2.properties
```

Agora configure os arquivos copiados.

No arquivo `server1.properties`, habilite e altere as op√ß√µes:

```bash
broker.id=1
listeners=PLAINTEXT://:9093
log.dirs=/tmp/kafka-logs-1
```

No arquivo `server2.properties`, habilite e altere as op√ß√µes:

```bash
broker.id=2
listeners=PLAINTEXT://:9094
log.dirs=/tmp/kafka-logs-2
```

Agora posso iniciar e testar o funcionamento do Kafka.

O primeiro passo para testar √© iniciar o Zookeeper pelo diret√≥rio `/opt/kafka`

```bash
bin/zookeeper-server-start.sh config/zookeeper.properties
```

![Zookeeper inicializado com sucesso!](/Imagens/Untitled%2095.png)

Zookeeper inicializado com sucesso!

Abra 3 sess√µes de terminal e em cada terminal execute as configura√ß√µes feitas dos brokers.

```bash
bin/kafka-server-start.sh config/server.properties
bin/kafka-server-start.sh config/server1.properties
bin/kafka-server-start.sh config/server2.properties
```

Verifique se a porta inicializada foi a inicializada de acordo com a configura√ß√£o feita.

Inicializa√ß√£o com o arquivo `server.properties`

![Untitled](/Imagens/Untitled%2096.png)

Inicializa√ß√£o com o arquivo `server1.properties`

![Untitled](/Imagens/Untitled%2097.png)

Inicializa√ß√£o com o arquivo `server2.properties`

![Untitled](/Imagens/Untitled%2098.png)

Abra uma nova sess√£o no terminal e crie um t√≥pico Kafka.

```bash
bin/kafka-topics.sh --create --topic BrokersTres --bootstrap-server localhost:9092 --replication-factor 3 --partitions 1
```

![Untitled](/Imagens/Untitled%2099.png)

Rode o comando abaixo para descrever o status do t√≥pico criado.

```bash
bin/kafka-topics.sh --describe --topic BrokersTres --bootstrap-server localhost:9092
```

![Untitled](/Imagens/Untitled%20100.png)

Inicialize o producer apontando o t√≥pico criado.

```bash
bin/kafka-console-producer.sh --topic BrokersTres --bootstrap-server localhost:9092
```

![Producer inicializado.](/Imagens/Untitled%20101.png)

Producer inicializado.

Abra uma nova sess√£o no terminal e inicialize o consumer apontando o t√≥pico criado, puxando mensagens desde o in√≠cio.

```bash
bin/kafka-console-consumer.sh --topic BrokersTres --from-beginning --bootstrap-server localhost:9092
```

Escreva mensagens no producer.

![Untitled](/Imagens/Untitled%20102.png)

Verifique se chegou corretamente no consumer.

![Untitled](/Imagens/Untitled%20103.png)

Tudo funcionando! Podemos encerrar todos os servi√ßos.

```bash
bin/zookeeper-server-stop.sh config/zookeeper.properties
bin/kafka-server-stop.sh config/server.properties
bin/kafka-server-stop.sh config/server1.properties
bin/kafka-server-stop.sh config/server2.properties
```

<br>

<a name = "Nifi"></a>
### Instala√ß√£o e configura√ß√£o do Apache Nifi

> **üí°**: Para a instala√ß√£o do Nifi, certifique que as m√°quinas estejam com Java JDK instalado.

A instala√ß√£o do Nifi ser√° na m√°quina local.

Primeiro passo √© fazer o Download do arquivo bin√°rio do Nifi:

![Untitled](/Imagens/Untitled%20104.png)

Copie o link de download do bin√°rio:

[https://dlcdn.apache.org/nifi/1.18.0/nifi-1.18.0-bin.zip](https://dlcdn.apache.org/nifi/1.18.0/nifi-1.18.0-bin.zip)

Conectado ao Namenode, no diret√≥rio `/opt/`, fa√ßa o Download do bin√°rio

```bash
sudo wget https://dlcdn.apache.org/nifi/1.18.0/nifi-1.18.0-bin.zip
```

![Untitled](/Imagens/Untitled%20105.png)

Ap√≥s finalizar o Download, √© necess√°rio descompact√°-lo, remover o arquivo compactado, alterar o nome e dono do arquivo.

```bash
sudo unzip nifi-1.18.0-bin.zip
sudo rm -rf nifi-1.18.0-bin.zip
sudo mv nifi-1.18.0/ /opt/nifi
```

Configurando as vari√°veis de ambiente no arquivo `~/.bash_profile`

```bash
export NIFI_HOME=/opt/nifi 
export PATH=$PATH:$NIFI_HOME/bin
```

Iniciando o Apache Nifi

> **üí°**: S√≥ ir√° rodar se voc√™ tiver o Java instalado em sua m√°quina local.

```bash
$NIFI_HOME/bin/nifi.sh start
```

![Untitled](/Imagens/Untitled%20106.png)

Crie um usu√°rio no Nifi

```bash
$NIFI_HOME/bin/nifi.sh set-single-user-credentials <usuario> <senha>
```

Acesse

```bash
https://localhost:8443/nifi/login
```

Utilize o login criado.

![Untitled](/Imagens/Untitled%20107.png)

![Untitled](/Imagens/Untitled%20108.png)

Desligue o Nifi

```bash
$NIFI_HOME/bin/nifi.sh stop
```

Instala√ß√£o do Nifi conclu√≠da.

<br>

<a name = "Spark"></a>
### Instala√ß√£o e configura√ß√£o do Apache Spark

> **üí°**: Para a instala√ß√£o do Spark, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

Primeiro passo √© fazer o Download do arquivo bin√°rio do Spark:

[https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html)

![Untitled](/Imagens/Untitled%20109.png)

Copie o link de Download do bin√°rio:

[https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz](https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz)

![Untitled](/Imagens/Untitled%20110.png)

Abra o terminal do Namenode, v√° ao diret√≥rio `/opt/` e insira o comando `wget` com o link bin√°rio do Spark:

> **üí°**: S√≥ ser√° poss√≠vel a execu√ß√£o do comando ==wget==, caso voc√™ tenha ele instalado.

```bash
sudo wget https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz
```

![Untitled](/Imagens/Untitled%20111.png)

Verificando, extraindo, removendo o arquivo compactado e alterando o nome do diret√≥rio.

```bash
ls -la
sudo tar xzf spark-3.3.1-bin-hadoop3.tgz
sudo rm -rf spark-3.3.1-bin-hadoop3.tgz
sudo mv spark-3.3.1-bin-hadoop3/ /opt/spark
```

![Untitled](/Imagens/Untitled%20112.png)

Adotando novamente outro padr√£o, estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake spark/
```

![Untitled](/Imagens/Untitled%20113.png)

Agora irei configurar as vari√°veis de ambiente do meu usu√°rio datalake inserindo as seguintes configura√ß√µes:

```bash
export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin
```

![Untitled](/Imagens/Untitled%20114.png)

Testando seu funcionamento.

```bash
spark-shell
```

![Untitled](/Imagens/Untitled%20115.png)

Utilize o atalho `CTRL+C` para fechar o `spark-shell`

<a name = "Cluster"></a>
<b>Configurando o Spark em Multinode Cluster</b>

Entre no diret√≥rio `/opt/spark/conf` e fa√ßa uma c√≥pia renomeada sem .template dos arquivos `spark-env.sh.template` e `workers.template`

```bash
cp spark-env.sh.template spark-env.sh
cp workers.template workers
```

Edite o arquivo `workers` e insira o IP dos Datanodes:

![Untitled](/Imagens/Untitled%20116.png)

Edite o arquivo `spark-env.sh` e insira

```bash
export SPARK_MASTER_HOST=namenode
export JAVA_HOME=/opt/jdk
```

![Untitled](/Imagens/Untitled%20117.png)

Para iniciar o Spark √© necess√°rio primeiro instalar-lo tamb√©m nas outras m√°quinas, estarei fazendo a c√≥pia do Namenode para os Datanodes.

Primeiramente √© necess√°rio criar o diret√≥rio do Spark nos Datanodes e alterar o dono do diret√≥rio.

```bash
sudo mkdir /opt/spark
sudo chown -R datalake:datalake /opt/spark/
```

![Untitled](/Imagens/Untitled%20118.png)

Fa√ßa a c√≥pia do Namenode para os Datanodes.

```bash
scp -rv -i "~/.ssh/id_rsa" /opt/spark datalake@datanode1:/opt
scp -rv -i "~/.ssh/id_rsa" /opt/spark datalake@datanode2:/opt
```

Verifique se chegou corretamente nos Datanodes.

![Untitled](/Imagens/Untitled%20119.png)

Agora podemos rodar o Multinode pelo Namenode

```bash
$SPARK_HOME/sbin/start-all.sh
```

![Untitled](/Imagens/Untitled%20120.png)

Verificando em todas as m√°quinas se os servi√ßos foram iniciados corretamente

```bash
jps
```

Namenode

![Untitled](/Imagens/Untitled%20121.png)

Datanode1

![Untitled](/Imagens/Untitled%20122.png)

Datanode2

![Untitled](/Imagens/Untitled%20123.png)

Inicie o `spark-shell`

```bash
spark-shell --master spark://namenode:7077
```

![Untitled](/Imagens/Untitled%20124.png)

Utilize o atalho `CTRL+C` para fechar o `spark-shell`

Verifique se todos os Datanodes est√£o sincronizados.

```bash
http://192.168.1.9:4040
```

![Untitled](/Imagens/Untitled%20125.png)

Tamb√©m √© poss√≠vel verificar atrav√©s do endere√ßo:

```bash
http://192.168.1.9:8080/
```

![Untitled](/Imagens/Untitled%20126.png)

Parando todos os servi√ßos

```bash
$SPARK_HOME/sbin/stop-all.sh
```

Instala√ß√£o do Spark conclu√≠da.

<br>

<a name = "Hive"></a>
### Instala√ß√£o e configura√ß√£o do Apache Hive

> **üí°**: Para a instala√ß√£o do Hive, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

Primeiro passo √© fazer o Download do arquivo bin√°rio do Hive:

[https://dlcdn.apache.org/hive/](https://dlcdn.apache.org/hive/)

![Untitled](/Imagens/Untitled%20127.png)

Escolha a vers√£o e copie o link de Download do bin√°rio:

[https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz](https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz)

![Untitled](/Imagens/Untitled%20128.png)

Abra o terminal do Namenode, v√° ao diret√≥rio `/opt/` e insira o comando `wget` com o link bin√°rio do Hive:

> **üí°**: S√≥ ser√° poss√≠vel a execu√ß√£o do comando ==wget==, caso voc√™ tenha ele instalado.

```bash
sudo wget https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz
```

![Untitled](/Imagens/Untitled%20129.png)

Verificando, extraindo, removendo o arquivo compactado e alterando o nome do diret√≥rio.

```bash
ls -la
sudo tar xzf apache-hive-3.1.3-bin.tar.gz 
sudo rm -rf apache-hive-3.1.3-bin.tar.gz 
sudo mv apache-hive-3.1.3-bin/ /opt/hive
```

![Untitled](/Imagens/Untitled%20130.png)

Estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake hive/
```

![Untitled](/Imagens/Untitled%20131.png)

Exportando as vari√°veis de ambiente:

```bash
export HIVE_HOME=/opt/hive
export PATH=$PATH:$HIVE_HOME/bin
```

![Untitled](/Imagens/Untitled%20132.png)

Verifique a vers√£o do Hive

```bash
hive --version
```

![Untitled](/Imagens/Untitled%20133.png)

Antes de inicializar √© necess√°rio ter um banco de dados relacional para armazenar o Metastore do Hive.

<br>

<a name = "Oracle"></a>
<b>Configura√ß√£o do Metastore com Banco de Dados Oracle</b>

√â necess√°rio o Download do conector JDBC do Oracle.

[https://www.oracle.com/br/database/technologies/appdev/jdbc-downloads.html](https://www.oracle.com/br/database/technologies/appdev/jdbc-downloads.html)

![Untitled](/Imagens/Untitled%20134.png)

Copie o link e fa√ßa o Download no diret√≥rio `/opt/hive/lib/`

```bash
sudo wget https://download.oracle.com/otn-pub/otn_software/jdbc/217/ojdbc8.jar
```

![Untitled](/Imagens/Untitled%20135.png)

Altere o dono e grupo do arquivo para datalake

```bash
sudo chown -R datalake:datalake ojdbc8.jar
```

Antes de qualquer passo √© necess√°rio iniciar o HDFS.

```bash
$HADOOP_HOME/sbin/start-dfs.sh
```

![Untitled](/Imagens/Untitled%20136.png)

Iniciando o banco de dados Oracle

![Untitled](/Imagens/Untitled%20137.png)

Utilizarei o SQL Developer para se conectar ao Oracle

Se conectando ao usu√°rio sys

![Untitled](/Imagens/Untitled%20138.png)

Criando um usu√°rio no banco de dados e dando privil√©gios:

![Untitled](/Imagens/Untitled%20139.png)

Testando a conex√£o

![Untitled](/Imagens/Untitled%20140.png)

Agora rode o script que √© disponibilizado pelo Hive no diret√≥rio 

```bash
/opt/hive/scripts/metastore/upgrade/oracle
```

Copie o conte√∫do dentro do arquivo `hive-schema-3.1.0.oracle.sql` e rode no SQL Developer.

![Untitled](/Imagens/Untitled%20141.png)

Agora √© necess√°rio configurar o Hive para se conectar com o banco Oracle

No diret√≥rio `/opt/hive/conf` crie o arquivo `hive-site.xml`

```bash
vi hive-site.xml
```

Dentro do arquivo insira as configura√ß√µes.

```html
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:oracle:thin:@//192.168.1.11/ORCL12C</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>oracle.jdbc.OracleDriver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
    </property>
</configuration>
```

![Untitled](/Imagens/Untitled%20142.png)

Rode o comando para criar o schema:

> **üí°**: Para funcionar corretamente √© necess√°rio configurar o arquivo ==tnsnames.ora== do banco de dados Oracle.

```bash
/opt/hive/bin/schematool -dbType oracle -initSchema
```

Agora √© s√≥ rodar o comando Hive.

> **üí°**: O comando ==hive== s√≥ vai funcionar se as vari√°veis de ambiente estiverem configuradas corretamente.

![Untitled](/Imagens/Untitled%20143.png)

Instala√ß√£o conclu√≠da.

<br>
<a name = "MySQL"></a>
<b>Configura√ß√£o do Metastore com Banco de Dados MySQL</b>

Baixar o conector JDBC do MySQL

[https://dev.mysql.com/downloads/connector/j/](https://dev.mysql.com/downloads/connector/j/)

![Untitled](/Imagens/Untitled%20144.png)

Utilize o comando wget para baixar no diret√≥rio `/opt/hive/lib`

```bash
sudo wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-j-8.0.31.zip
```

![Untitled](/Imagens/Untitled%20145.png)

Ap√≥s baixar √© hora de extrair:

```bash
sudo unzip mysql-connector-j-8.0.31.zip
```

![Untitled](/Imagens/Untitled%20146.png)

Removendo o arquivo baixado.

```bash
sudo rm -rf mysql-connector-j-8.0.31.zip
```

Entre no diret√≥rio `mysql-connector-j-8.0.31`

```bash
cd /opt/hive/lib/mysql-connector-j-8.0.31
```

Mova o `mysql-connector-j-8.0.31.jar` para o `/opt/hive/lib/`

```bash
sudo mv mysql-connector-j-8.0.31.jar /opt/hive/lib
```

Altere o dono e grupo do arquivo `mysql-connector-j-8.0.31.jar` 

```bash
sudo chown -R datalake:datalake mysql-connector-j-8.0.31.jar
```

Agora crie um banco de dados no MySQL

Inicie o MySQL

```bash
mysql -u root -p
```

![Untitled](/Imagens/Untitled%20147.png)

```sql
CREATE DATABASE METASTORE;
```

![Untitled](/Imagens/Untitled%20148.png)

Entre no banco criado.

```sql
USE METASTORE;
```

![Untitled](/Imagens/Untitled%20149.png)

Agora crie o schema do Hive

```sql
source /opt/hive/scripts/metastore/upgrade/mysql/hive-schema-3.1.0.mysql.sql
```

![Untitled](/Imagens/Untitled%20150.png)

Cria√ß√£o de um usu√°rio para a conex√£o do Hive.

```sql
CREATE USER 'hive' IDENTIFIED BY 'eYsfh$99N6';
```

![Untitled](/Imagens/Untitled%20151.png)

Concess√£o de privil√©gios para o usu√°rio `hive`

```sql
GRANT ALL PRIVILEGES ON *.* TO hive;
flush privileges;
```

![Untitled](/Imagens/Untitled%20152.png)

Agora √© hora de configurar o Hive.

Entre no diret√≥rio `/opt/hive/conf`,crie o arquivo `hive-site.xml` e insira as configura√ß√µes.

```html
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>eYsfh$99N6</value>
    </property>
</configuration>
```

Tudo configurado, agora podemos rodar o Hive, para isso √© necess√°rio antes rodar o HDFS e o Yarn.

```bash
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/yarn-dfs.sh
```

![Untitled](/Imagens/Untitled%20153.png)

Antes de rodar o hive √© necess√°rio tirar o HDFS do modo Safe:

```bash
hdfs dfsadmin -safemode leave
```

Rode o comando para iniciar o schema criado no MySQL.

```bash
schematool -dbType mysql -initSchema
```

![Untitled](/Imagens/Untitled%20154.png)

Agora rodamos o comando `Hive`

![Untitled](/Imagens/Untitled%20155.png)

Conclu√≠do a instala√ß√£o

<br>
<a name = "HiveTest"></a>
<b>Testando o Hive</b>

Para testar o Hive primeiramente irei criar uma tabela nele.

```sql
CREATE TABLE datalake (COL1 INT);
```

![Untitled](/Imagens/Untitled%20156.png)

Verificando o Metastore pelo banco de dados MySQL. 

```sql
USE METASTORE;
SELECT * FROM TBLS;
```

![Untitled](/Imagens/Untitled%20157.png)

Metastore da tabela Hive (Datalake) criada com sucesso!

Para esse teste vou incluir arquivos `.csv` no meu HDFS. Estarei utilizando como base um arquivo `.csv` da minha autoria e o repartir em 3 arquivos.

![Untitled](/Imagens/Untitled%20158.png)

Criando a pasta cliente e movendo os arquivos `.csv` para dentro dela.

```bash
hdfs dfs -mkdir /cliente
hdfs dfs -mv /cliente1.csv /cliente
hdfs dfs -mv /cliente2.csv /cliente
hdfs dfs -mv /cliente3.csv /cliente
hdfs dfs -ls /cliente
```

![Untitled](/Imagens/Untitled%20159.png)

Estruturando arquivos `.csv` para rodar no Hive.

```sql
CREATE EXTERNAL TABLE Cliente (
CPF STRING,
NOME STRING,
SOBRENOME STRING,
DATA_NASCIMENTO STRING,
ID_ENDERECO STRING,
EMAIL STRING,
CONTATO STRING,
SALARIO STRING,
DATA_INICIO STRING,
DATA_FIM STRING,
ID_FUNCIONARIO STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
location '/cliente/';
```

![Untitled](/Imagens/Untitled%20160.png)

Executando uma query

```sql
SELECT * FROM CLIENTE;
```

![Untitled](/Imagens/Untitled%20161.png)

Conclu√≠do o teste com o Hive!

Ap√≥s todas essas instala√ß√µes, o Data Lake est√° pronto para uso.