Link para o projeto no 
[Notion](https://castroiwnl.notion.site/castroiwnl/Data-Lake-On-Premises-9845115c23374331a7a65c658fe3eeb1)

Link para o projeto no
[Site](https://alexandre-castro.vercel.app/blog/datalake-premises)


- Preparando as m√°quinas

Antes de qualquer passo, para este projeto, estarei utilizando o Virtualbox da Oracle para a virtualiza√ß√£o das m√°quinas, mas n√£o √© obrigat√≥rio a utiliza√ß√£o deste, podendo ser qualquer outro virtualizador, desde de que seja poss√≠vel a configura√ß√£o de rede das m√°quinas.


Iniciar o Virtualbox e selecionar a op√ß√£o:

- Novo

![Captura de tela de 2022-11-09 10-38-04.png](Datalake/Captura_de_tela_de_2022-11-09_10-38-04.png)

Segue o modelo de cria√ß√£o das diferentes m√°quinas:

- **Cria√ß√£o do Namenode**

<aside>
üí° √â obrigat√≥rio a cria√ß√£o do Namenode, por mais que um dia n√£o v√° utilizar nenhum Datanode.

</aside>

Escolha um nome para a sua m√°quina que ser√° o Namenode, seguindo essas configura√ß√µes de tipo e vers√£o, pois estaremos utilizando o CentOS como sistema operacional.

Selecione a op√ß√£o:

- Pr√≥ximo (N) >

![Untitled](Datalake/Untitled.png)

Em seguida selecione a quantidade de mem√≥ria que ser√° alocada a m√°quina, para o Namenode √© importante que seja um pouco mais forte do que os Datanodes, j√° que ele que ser√° o orquestrador do Hadoop, neste caso estarei alocando **4GB** de mem√≥ria RAM.

Selecione a op√ß√£o:

- Pr√≥ximo (N) >

![Untitled](Datalake/Untitled%201.png)

Cria√ß√£o do disco r√≠gido virtual para armazenamento dos dados da m√°quina.

Selecione a op√ß√£o:

- Criar um novo disco r√≠gido virtual agora
- Pr√≥ximo (N) >

![Untitled](Datalake/Untitled%202.png)

Selecione a op√ß√£o:

- VDI (VirtualBOX Disk Image)
- Pr√≥ximo (N) >

![Untitled](Datalake/Untitled%203.png)

Selecione a op√ß√£o:

- Dinamicamente alocado

<aside>
üí° Importante que o disco seja dinamicamente alocado para n√£o ocupar todo o espa√ßo reservado em sua m√°quina f√≠sica.

</aside>

- Pr√≥ximo (N) >

![Untitled](Datalake/Untitled%204.png)

Selecione a quantidade que ser√° alocada dinamicamente no disco virtual, recomendo no m√≠nimo **10GB**, estarei colocando **20GB** para ter uma margem a mais mantendo o diret√≥rio padr√£o de onde ser√° armazenado o disco virtual.

Selecione a op√ß√£o:

- Criar

![Untitled](Datalake/Untitled%205.png)

Ap√≥s isso, foi criado o Namenode, agora temos que alterar as configura√ß√µes de rede, para as m√°quinas poderem se comunicarem entre si.

Selecione a op√ß√£o:

- Configura√ß√µes

![Untitled](Datalake/Untitled%206.png)

Abrir√° a tela de configura√ß√µes, v√° na aba Rede.

Clique em:

- Conectado e selecione a op√ß√£o ‚ÄòPlaca em modo Bridge‚Äô
- Clique em OK

![Untitled](Datalake/Untitled%207.png)

Seguindo esses passos, o Namenode agora est√° habilitado a ter seu IP pr√≥prio para realizar a configura√ß√£o de conex√£o entre os clusters.

- **Cria√ß√£o do Datanode**

Para sua cria√ß√£o, seguiremos praticamente os mesmos passos da cria√ß√£o do Namenode, com apenas duas altera√ß√µes.

A primeira altera√ß√£o ser√° no nome da m√°quina, neste caso ser√° o Datanode1

<aside>
üí° Estarei utilizando 2 Datanodes para a forma√ß√£o do meu datalake, mas n√£o √© obrigat√≥rio possuir Datanodes, ou apenas 2 Datanodes, pode ser criado infinitos Datanodes, desde que voc√™ tenha capacidade computacional para isso.

</aside>

![Untitled](Datalake/Untitled%208.png)

A segunda altera√ß√£o ser√° na quantidade de mem√≥ria, alocarei apenas **2GB**, porque como citei na cria√ß√£o do Namenode, os Datanodes podem ter menos poder computacional.

![Untitled](Datalake/Untitled%209.png)



---

- Instala√ß√£o do CentOS

Para a instala√ß√£o do sistema operacional, √© necess√°rio baixar a ISO dele, neste caso estarei utilizando a vers√£o Minimal do CentOS, para baixo consumo de recursos e ganho de performance nos clusters.


Acesse a p√°gina de Download do CentOS

[https://www.centos.org/download/](https://www.centos.org/download/)

Estarei utilizando a vers√£o x86_64

Selecione a op√ß√£o:

- x86_64

<aside>
üí° Tamb√©m √© poss√≠vel escolher outras vers√µes caso a x86_64 n√£o seja compat√≠vel com seu virtualizador ou m√°quina.

</aside>

![Untitled](Datalake/Untitled%2010.png)

Selecione um dos mirrors de Download, estarei selecionando o [primeiro](http://mirror.uepg.br/centos/7.9.2009/isos/x86_64/)

![Untitled](Datalake/Untitled%2011.png)

Selecione a op√ß√£o:

- CentOS-7-x86_64-Minimal-2009.iso

![Untitled](Datalake/Untitled%2012.png)

Ap√≥s realizar o Download √© hora de instalar o CentOS nas m√°quinas que foram criadas.

- **Instala√ß√£o do CentOS no Namenode**

Abra o Virtual Box, clique no Namenode.

<aside>
üí° M√°quina criada na etapa anterior.

</aside>

Selecione a op√ß√£o:

- Iniciar (T)

![Untitled](Datalake/Untitled%2013.png)

Abra essa janela, clique no s√≠mbolo da pasta ao lado do campo de sele√ß√£o.

![Untitled](Datalake/Untitled%2014.png)

Selecione o diret√≥rio da ISO do CentOS (CentOS-7-x86_64-Minimal-2009.iso).

Clique em:

- Acrescentar

![Untitled](Datalake/Untitled%2015.png)

Ap√≥s selecionar a ISO clique em:

- Iniciar

![Untitled](Datalake/Untitled%2016.png)

Ap√≥s iniciar, selecione a op√ß√£o:

- Install CentOS 7

![Untitled](Datalake/Untitled%2017.png)

Ap√≥s as telas de logs, aparecer√° o instalador do CentOS.

Nesta tela voc√™ configura as linguagens do SO, no meu caso deixarei no padr√£o (English).

Selecione a op√ß√£o:

- Continue

![Untitled](Datalake/Untitled%2018.png)

Agora vou configurar as op√ß√µes de regi√£o, data e hora.

Selecione a op√ß√£o:

- DATE & TIME

![Untitled](Datalake/Untitled%2019.png)

Marque a regi√£o mais pr√≥xima de onde voc√™ se localiza

Selecione a op√ß√£o:

- Done

![Untitled](Datalake/Untitled%2020.png)

Indicando o destino de onde ser√° instalado o SO.

Des√ßa a tela e selecione a op√ß√£o:

- INSTALLATION DESTINATION

![Untitled](Datalake/Untitled%2021.png)

Marque o disco virtual criado na etapa anterior.

Selecione a op√ß√£o:

- Done

![Untitled](Datalake/Untitled%2022.png)

Configura√ß√£o de rede e nome do Host

Selecione a op√ß√£o:

- NETWORK & HOST NAME

![Untitled](Datalake/Untitled%2023.png)

Marque a caixinha como ON embaixo do ‚Äòbot√£o Help!‚Äô, para habilitar a internet na m√°quina

Altere o Host name para o nome da sua m√°quina criada na etapa anterior e clique em:

- Apply
- Done

![Untitled](Datalake/Untitled%2024.png)

Come√ßar a instala√ß√£o do SO.

Clique em:

- Begin Installation

![Untitled](Datalake/Untitled%2025.png)

Configura√ß√£o da senha do usu√°rio Root

Clique em:

- ROOT PASSWORD

![Untitled](Datalake/Untitled%2026.png)

Definindo uma senha para o Root

Insira uma senha segura e clique em:

- Done

![Untitled](Datalake/Untitled%2027.png)

Cria√ß√£o de um usu√°rio

Clique em:

- USER CREATION

![Untitled](Datalake/Untitled%2028.png)

Preencha o nome do usu√°rio e crie uma senha segura para ele, depois clique em:

- Done

![Untitled](Datalake/Untitled%2029.png)

Ap√≥s toda a configura√ß√£o, espere a barra de instala√ß√£o completar e aperte o bot√£o:

- Reboot

![Untitled](Datalake/Untitled%2030.png)

- **Instala√ß√£o do CentOS no Datanode**

A instala√ß√£o no Datanode √© praticamente igual ao do Namenode, por√©m √© necess√°rio alterar o Host name para o nome da sua m√°quina Datanode, repita esse processo para todos os Datanodes.

![Untitled](Datalake/Untitled%2031.png)



---

- Configura√ß√£o inicial do Linux

Para come√ßar a configurar as m√°quinas, estarei me conectando atrav√©s do SSH da minha m√°quina local nas m√°quinas virtuais no terminal.

Como a minha m√°quina principal tamb√©m √© Linux, eu consigo diretamente pelo terminal utilizar o comando SSH para me conectar nas m√°quinas, para isso, antes √© necess√°rio ligar o Namenode e os Datanodes, no meu caso 2 Datanodes.

<aside>
üí° Para usu√°rios de Windows:
Se voc√™ tentar se conectar pelo PowerShell do Windows, voc√™ n√£o conseguir√°, para solucionar isso baixe o Putty e fa√ßa a conex√£o diretamente dele.

</aside>

Abra o Virtual Box

Selecione o Namenode e os Datanodes e clique em:

- Iniciar (T)

![Untitled](Datalake/Untitled%2032.png)

Abrir√° neste menu.

Selecione a primeira op√ß√£o apertando o ‚ÄòEnter‚Äô do teclado.

![Untitled](Datalake/Untitled%2033.png)

Ap√≥s iniciar e aguardar os logs de inicializa√ß√£o, fa√ßa o login criado na instala√ß√£o, realizado na  etapa anterior.

![Untitled](Datalake/Untitled%2034.png)

Repita esse processo para todos os Datanodes.

Datanode1:

![Untitled](Datalake/Untitled%2035.png)

Datanode2: 

![Untitled](Datalake/Untitled%2036.png)

Ap√≥s ligar e logar em todas m√°quinas, precisamos do IP de cada uma delas para realizar a conex√£o via SSH. Entre em cada m√°quina e colete o IP delas atrav√©s do comando:

```bash
ip a 
```

![Untitled](Datalake/Untitled%2037.png)

IP das minhas m√°quinas:

```bash
Namenode: 192.168.1.16
Datanode1: 192.168.1.14
Datanode2: 192.168.1.15
```

<aside>
üí° Vale ressaltar que esses IP‚Äôs n√£o ser√£o necessariamente iguais aos meus (mesmo podendo ser tamb√©m), por isso √© importante anotar eles.

</aside>

Ap√≥s as coletas, abra o Terminal da sua m√°quina local e insira o comando:

```bash
ssh usu√°rio@ipdamaquina 
```

Depois aparecer√° este aviso:

`Are you sure you want to continue connecting (yes/no/[fingerprint])?`

Digite `yes`. Depois ser√° solicitado a senha do usu√°rio, digite ela e estar√° conectado.

<aside>
üí° Usu√°rio criado na instala√ß√£o do CentOS

</aside>

Conectando com a minha m√°quina no Namenode:

<aside>
üí° Para usu√°rios de Windows: 
√â hora de usar o Putty e fazer a conex√£o via SSH.

</aside>

```bash
ssh datalake@192.168.1.16
```

![Neste momento j√° estou conectado ao meu Namenode pelo SSH na minha m√°quina local.](Datalake/Untitled%2038.png)

Neste momento j√° estou conectado ao meu Namenode pelo SSH na minha m√°quina local.

Repita esse processo novamente para todos os Datanodes abrindo mais janelas no terminal.

Conex√£o com o Datanode1:

```bash
ssh datalake@192.168.1.14
```

![Untitled](Datalake/Untitled%2039.png)

Conex√£o com o Datanode2:

```bash
ssh datalake@192.168.1.15
```

![Untitled](Datalake/Untitled%2040.png)

Agora, estamos oficialmente 100% prontos para as configura√ß√µes do Linux.

- **Configura√ß√£o do Sudoers**

<aside>
üí° √â necess√°rio realizar esse passo para todas as m√°quinas.

</aside>

Para poder realizar os comandos de Root no usu√°rio datalake, √© necess√°rio configurar o arquivo sudoers. 

Primeiro passo, entre no root:

```bash
su - 
```

Edite o arquivo sudoers:

```bash
vi /etc/sudoers
```

Insira dentro do arquivo o nome do usu√°rio datalake.

```bash
datalake    ALL=(ALL)    ALL
```

![Untitled](Datalake/Untitled%2041.png)

Salve o arquivo e saia do perfil Root, executando o comando:

```bash
exit
```

- **Atualizando o sistema**

<aside>
üí° √â necess√°rio realizar esse passo para todas as m√°quinas.

</aside>

Ap√≥s a configura√ß√£o do arquivo `sudoers` e acesso do Linux com o usu√°rio datalake vou verificar se possui atualiza√ß√µes e se sim, realizar elas.

```bash
sudo yum update
```

Quando terminar a atualiza√ß√£o ele mostrar√° uma mensagem de conclu√≠do na tela.

![Untitled](Datalake/Untitled%2042.png)

- **Configurando o arquivo hosts**

Para as m√°quinas poderem se comunicar entre si, temos que configurar as chaves de seguran√ßa SSH, para esta tarefa precisamos primeiro configurar o arquivo hosts das nossas m√°quinas.

Para modificar o arquivo hosts, use o comando:

```bash
sudo vi /etc/hosts 
```

Informe para o arquivo hosts qual s√£o os IP‚Äôs das m√°quinas que ele far√° conex√£o e ao seu lado coloque o nome indicativo de qual m√°quina est√° apontando o IP.

```bash
192.168.1.14   datanode1
192.168.1.15   datanode2
```

![Untitled](Datalake/Untitled%2043.png)

Repita esse processo para todas as m√°quinas modificando os IP‚Äôs e nomes das m√°quinas.

![Untitled](Datalake/Untitled%2044.png)

Depois de configurado, devemos testar para ver se as m√°quinas est√£o se comunicando entre-si, s√≥ rodar o comando em qualquer m√°quina:

```bash
ping datanode1 
ping datanode2
```

![Caso o ping esteja retornando os milissegundos entre as conex√µes, significa que foi configurado corretamente.](Datalake/Untitled%2045.png)

Caso o ping esteja retornando os milissegundos entre as conex√µes, significa que foi configurado corretamente.

- **Configurando o arquivo sshd_config**

Para habilitar a conex√£o via SSH entre m√°quinas √© necess√°rio configurar o arquivo sshd_config, nele est√£o as configura√ß√µes de conex√£o do SSH.

<aside>
üí° √â necess√°rio realizar todos passos seguintes em todas as m√°quinas.
</aside>

Para editar este arquivo, rodamos o comando:

```bash
sudo vi /etc/ssh/sshd_config
```

Ap√≥s abrir o editor no arquivo, √© necess√°rio remover o coment√°rio dos comandos:

```bash
Port 22
ListenAddress 0.0.0.0
ListenAddress ::
PubkeyAuthentication yes
```

![Untitled](Datalake/Untitled%2046.png)

Por √∫ltimo reinicie o servi√ßo do sshd para alterar as configura√ß√µes feitas:

```bash
sudo systemctl restart sshd
```

Pronto! Arquivo `sshd` devidamente configurado. 

- **Configurando as chaves de seguran√ßa SSH**

Ap√≥s a configura√ß√£o do arquivo hosts e arquivo sshd, agora √© hora de configurar o SSH.

A configura√ß√£o da chave SSH far√° com que as m√°quinas se comuniquem sem precisarem de senhas no momento em que algo for feito entre as m√°quinas.

<aside>
üí° √â necess√°rio realizar todos passos seguintes apenas no Namenode

</aside>

Para gerar a chave de SSH, precisamos estar em nosso Namenode e rodar o comando:

```bash
ssh-keygen
```

Caso queira fazer alguma modifica√ß√£o na chave, voc√™ tem essa op√ß√£o, no meu caso vou deixar tudo como padr√£o, seguindo apertando ‚ÄòEnter‚Äô para gerar a chave.

<aside>
üí° Vale ressaltar que essa chave foi criada no usu√°rio datalake, cada chave √© gerada em cada usu√°rio. Caso tente ver essa chave em outro usu√°rio da mesma m√°quina, n√£o conseguir√°.

</aside>

![Untitled](Datalake/Untitled%2047.png)

Para verificar a cria√ß√£o da chave utilize o comando:

```bash
cat ~/.ssh/nomedachave
```

No meu caso a chave criada se chama id_rsa (padr√£o)

comando: 

```bash
cat ~/.ssh/id_rsa
```

![Untitled](Datalake/Untitled%2048.png)

Chave gerada! √â necess√°rio copiar essa chave para o pr√≥prio usu√°rio datalake

```bash
ssh-copy-id -i ~/.ssh/id_rsa datalake@namenode
```

Essa chave tamb√©m precisa ser copiada para as outras m√°quinas fazendo com que elas se comuniquem.

```bash
ssh-copy-id -i ~/.ssh/chave usuario@datanode
```

C√≥pia da chave para os Datanodes.

```bash
ssh-copy-id -i ~/.ssh/id_rsa datalake@datanode1
ssh-copy-id -i ~/.ssh/id_rsa datalake@datanode2
```

![Ser√° solicitado a confirma√ß√£o da conex√£o, s√≥ responder com `yes` e tamb√©m ser√° solicitado a senha do usu√°rio.](Datalake/Untitled%2049.png)

Ser√° solicitado a confirma√ß√£o da conex√£o, s√≥ responder com `yes` e tamb√©m ser√° solicitado a senha do usu√°rio.

<aside>
üí° S√≥ foi poss√≠vel utilizar o nome do host Datanode1 por conta da configura√ß√£o do arquivos hosts, caso o arquivos hosts n√£o estivesse configurado, o nome do host poderia ser substitu√≠do pelo IP do host.

</aside>

Repita esse comando para todos os Datanodes.

<aside>
üí° C√≥pia da chave para o Datanode2

</aside>

![Untitled](Datalake/Untitled%2050.png)

Para verificar o funcionamento da chave, vou conectar atrav√©s do SSH nos Datanodes.

```bash
ssh datalake@datanode1 -i ~/.ssh/id_rsa
ssh datalake@datanode2 -i ~/.ssh/id_rsa
```

![Conex√£o feita com sucesso, sem solicitar a senha, perceba que agora possui duas janelas de Datanode1. Verifique se os outros Datanodes tamb√©m est√£o se conectando via SSH sem pedir senha.](Datalake/Untitled%2051.png)

Conex√£o feita com sucesso, sem solicitar a senha, perceba que agora possui duas janelas de Datanode1. Verifique se os outros Datanodes tamb√©m est√£o se conectando via SSH sem pedir senha.

Ap√≥s isso podemos sair da conex√£o e voltar para o Namenode, utilizando o comando:

```bash
exit
```

Chave configurada, tudo oficialmente pronto para o in√≠cio da instala√ß√£o do Hadoop.



---

- Instala√ß√£o e configura√ß√£o do Java JDK 8

Maior parte das aplica√ß√µes da Apache roda sobre o Java, para isso devemos instalar o Java JDK, estarei utilizando a vers√£o 8 porque √© compat√≠vel com maior parte dos componentes, por mais que a vers√£o do Hadoop atual suporte o Java 11.
 

<aside>
üí° Certifique-se de que todas as m√°quinas est√£o ligadas.

</aside>

**Download do Java 8**

Para isso √© necess√°rio baixar o Java JDK 8 atrav√©s do seguinte link:

[https://www.oracle.com/br/java/technologies/javase/javase8-archive-downloads.html](https://www.oracle.com/br/java/technologies/javase/javase8-archive-downloads.html)

Estarei selecionando a vers√£o de Linux x64 compactada.

Baixe a op√ß√£o na sua m√°quina local:

- jdk-8u202-linux-x64.tar.gz

<aside>
üí° Estarei selecionando essa op√ß√£o, mas n√£o √© obrigat√≥rio, baixe a compat√≠vel com a sua m√°quina.

</aside>

![Untitled](Datalake/Untitled%2052.png)

Ser√° solicitado o login, caso n√£o tenha, fa√ßa um cadastro no site da Oracle.

[https://profile.oracle.com/myprofile/account/create-account.jspx](https://profile.oracle.com/myprofile/account/create-account.jspx)

![Untitled](Datalake/Untitled%2053.png)

Ap√≥s o login o Download ser√° iniciado automaticamente.

**Copiando o Java para as m√°quinas**

Depois de baixar, faremos a c√≥pia desse arquivo.

Abra o terminal da sua m√°quina local, onde foi baixado o Java e execute o comando:

```bash
scp /caminho/jdk-8u202-linux-x64.tar.gz root@ipdonamenode:/opt
```

![Untitled](Datalake/Untitled%2054.png)

Fa√ßa a c√≥pia do Java para os Datanodes tamb√©m

```bash
scp /caminho/jdk-8u202-linux-x64.tar.gz root@ipdodatanode:/opt
```

![Untitled](Datalake/Untitled%2055.png)

Ap√≥s a execu√ß√£o, verifique se a c√≥pia realmente foi feita. Acesse o diret√≥rio `/opt/` das m√°quinas e execute o comando `ls -la` para verificar se o arquivo foi realmente copiado

![Untitled](Datalake/Untitled%2056.png)

Ap√≥s verificar estamos preparados para instalar o Java.

<aside>
üí° √â necess√°rio realizar todos passos seguintes em todas as m√°quinas.

</aside>

**Instala√ß√£o do Java 8**

Para a instala√ß√£o, o primeiro passo √© extrair o conte√∫do do arquivo jdk-8u202-linux-x64.tar.gz,

para isso utilizaremos o comando, respons√°vel por extrair os arquivos:

```bash
sudo tar xzf jdk-8u202-linux-x64.tar.gz
```

Verificando se foi extra√≠do corretamente:

```bash
ls -la
```

![Untitled](Datalake/Untitled%2057.png)

Agora irei apagar o arquivo compactado, renomear o diret√≥rio criado para JDK e alterar o dono e grupo, seguindo uma boa pr√°tica de padroniza√ß√£o.

```bash
sudo rm -rf jdk-8u202-linux-x64.tar.gz
sudo mv jdk1.8.0_202/ /opt/jdk
ls -la
sudo chown -R root:root jdk/
```

![Untitled](Datalake/Untitled%2058.png)

Para dar continuidade a instala√ß√£o, precisa configurar as vari√°veis de ambiente, para isso edite o arquivo `.bash_profile`, localizado no `~/`

Insira as seguintes configura√ß√µes no arquivo, indicando o caminho do Java:

```bash
export JAVA_HOME=/opt/jdk
export JRE_HOME=/opt/jdk/jre
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
```

![Untitled](Datalake/Untitled%2059.png)

Para atualizar o arquivo de vari√°veis de ambiente rode o comando 

```bash
source .bash_profile
```

Para verificar se tudo est√° configurado corretamente, rode o comando 

```bash
java -version
```

![Caso apare√ßa a vers√£o, significa que tudo est√° corretamente configurado.](Datalake/Untitled%2060.png)

Caso apare√ßa a vers√£o, significa que tudo est√° corretamente configurado.

Agora √© poss√≠vel a instala√ß√£o do Hadoop.


---

- Instala√ß√£o e configura√ß√£o do Apache Hadoop

<aside>
üí° Para a instala√ß√£o do Hadoop, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

</aside>

Primeiro passo √© fazer o Download do arquivo bin√°rio do Hadoop 3.3.4:

[https://hadoop.apache.org/releases.html](https://hadoop.apache.org/releases.html)

![Untitled](Datalake/Untitled%2061.png)

Copie o link de Download

[https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz](https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz)

![Untitled](Datalake/Untitled%2062.png)

Abra o terminal do Namenode, v√° ao diret√≥rio `/opt/` e insira o comando `wget` com o link do Hadoop:

<aside>
üí° S√≥ ser√° poss√≠vel a execu√ß√£o do comando wget, caso voc√™ tenha ele instalado.

</aside>

```bash
sudo wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz
```

![Untitled](Datalake/Untitled%2063.png)

Verificando, extraindo, removendo o arquivo compactado e alterando o nome do diret√≥rio.

```bash
ls -la
sudo tar xzf hadoop-3.3.4.tar.gz
sudo rm -rf hadoop-3.3.4.tar.gz
sudo mv hadoop-3.3.4/ /opt/hadoop
```

![Untitled](Datalake/Untitled%2064.png)

Adotando novamente outro padr√£o, estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake hadoop/
```

![Untitled](Datalake/Untitled%2065.png)

Agora irei configurar as vari√°veis de ambiente do meu usu√°rio datalake inserindo as seguintes configura√ß√µes:

```bash
export HADOOP_HOME=/opt/hadoop
export HADOOP_CONF_DIR="${HADOOP_HOME}/etc/hadoop"
export PATH=$PATH:$HADOOP_HOME/bin
```

![Untitled](Datalake/Untitled%2066.png)

Agora podemos testar a vers√£o do Hadoop, caso as vari√°veis de ambiente tenham sido corretamente configuradas.

```bash
hadoop version
```

![Untitled](Datalake/Untitled%2067.png)

- **Configura√ß√£o do Hadoop**

Ap√≥s a instala√ß√£o e configura√ß√£o das vari√°veis de ambiente, precisamos configurar o Hadoop, para isso √© necess√°rio entrar no diret√≥rio: `/opt/hadoop/etc/hadoop`

Come√ßarei configurando o arquivo `hadoop-env.sh`, insira ou habilite as seguintes linhas no arquivo:

```bash
export JAVA_HOME=/opt/jdk
export HADOOP_HOME=/opt/hadoop
export HADOOP_CONF_DIR="${HADOOP_HOME}/etc/hadoop"
export PATH="${PATH}:${HADOOP_HOME}/bin"
export HADOOP_SSH_OPTS="-i ~/.ssh/id_rsa"
```

![Untitled](Datalake/Untitled%2068.png)

Configurando o arquivo `core-site.xml`

Apague as tags `configuration`.

<aside>
üí° Muito cuidado apagando este tipo de arquivo para n√£o apagar as indenta√ß√µes.

</aside>

![Untitled](Datalake/Untitled%2069.png)

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://namenode:19000</value>
    </property>
</configuration>
```

![Untitled](Datalake/Untitled%2070.png)

Configurando o `hdfs-site.xml`

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/hadoop/dfs/namespace_logs</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop/dfs/data</value>
    </property>
</configuration>
```

![Untitled](Datalake/Untitled%2071.png)

Configurando o `mapred-site.xml`

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>mapreduce.job.user.name</name>
        <value>hadoop</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>namenode:8032</value>
    </property>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
    </property>
</configuration>
```

![Untitled](Datalake/Untitled%2072.png)

Configurando o `yarn-site.xml`

Insira as seguintes configura√ß√µes:

```html
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>namenode</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>1536</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>1536</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>128</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>yarn.server.resourcemanager.application.expiry.interval</name>
        <value>60000</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>-1</value>
    </property>
    <property>
        <name>yarn.application.classpath</name>
        <value>$HADOOP_CONF_DIR,${HADOOP_COMMON_HOME}/share/hadoop/common/*,${HADOOP_COMMON_HOME}/share/hadoop/common/lib/*,${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*,${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*,${HADOOP_MAPRED_HOME}/share/hadoop/mapreduce/*,${HADOOP_MAPRED_HOME}/share/hadoop/mapreduce/lib/*,${HADOOP_YARN_HOME}/share/hadoop/yarn/*,${HADOOP_YARN_HOME}/share/hadoop/yarn/lib/*</value>`

    </property>
</configuration>
```

![Untitled](Datalake/Untitled%2073.png)

Por √∫ltimo a configura√ß√£o do arquivo `workers`, nele ser√£o inseridos os Datanodes que far√£o comunica√ß√£o com o Namenode. Insira o nome dos Datanodes.

<aside>
üí° Esses nomes s√£o das m√°quinas configuradas no arquivo `hosts`.

</aside>

![Untitled](Datalake/Untitled%2074.png)

Configura√ß√£o finalizada, mas antes de rodar o Hadoop, precisamos criar os diret√≥rios onde ser√£o salvo os logs e registros do HDFS, para isso executei os comandos:

```bash
mkdir /opt/hadoop/dfs
mkdir /opt/hadoop/dfs/data
mkdir /opt/hadoop/dfs/namespace_logs
```

Ap√≥s a instala√ß√£o do Hadoop,  tamb√©m √© necess√°rio realizar esse processo nos Datanodes, para n√£o precisar repetir todo processo novamente.

Farei a c√≥pia do diret√≥rio do Hadoop no Namenode, para os Datanodes.

Para fazer a copiar do Hadoop para os Datanodes, √© essencial que seja criado a pasta dele antes de receber a c√≥pia do diret√≥rio.

<aside>
üí° Fa√ßa isso para todos os Datanodes.

</aside>

```bash
sudo mkdir /opt/hadoop 
```

![Untitled](Datalake/Untitled%2075.png)

Caso esteja usando o padr√£o que estou seguindo, √© importante alterar o dono e o grupo do diret√≥rio para datalake, igualmente feito no Namenode.

```bash
sudo chown -R datalake:datalake hadoop/
```

![Untitled](Datalake/Untitled%2076.png)

Agora posso fazer a c√≥pia do diret√≥rio Hadoop configurado no Namenode para os Datanodes, utilizando a chave de seguran√ßa SSH.

```bash
scp -rv -i "~/.ssh/id_rsa" /opt/hadoop datalake@datanode1:/opt
scp -rv -i "~/.ssh/id_rsa" /opt/hadoop datalake@datanode2:/opt
```

Ao terminar a c√≥pia aparecer√° essa tela:

![Untitled](Datalake/Untitled%2077.png)

Acesse a pasta `/opt/hadoop` nos Datanodes e execute o comando `ls` para verificar se os arquivos chegaram corretamente.

![Untitled](Datalake/Untitled%2078.png)

Fim da instala√ß√£o do Hadoop, agora, utilizando o Namenode formatei o HDFS

```bash
hadoop namenode -format
```

![Untitled](Datalake/Untitled%2079.png)

- **Inicializa√ß√£o do Hadoop**

Ap√≥s a formata√ß√£o do HDFS, iniciarei todos os servi√ßos do Hadoop.

```bash
$HADOOP_HOME/sbin/start-all.sh
```

![Untitled](Datalake/Untitled%2080.png)

Verificando atrav√©s do terminal se os servi√ßos foram iniciados corretamente nas m√°quinas.

```bash
jps
```

![Untitled](Datalake/Untitled%2081.png)

![Untitled](Datalake/Untitled%2082.png)

![Untitled](Datalake/Untitled%2083.png)

Importando um arquivo teste e listando ele no HDFS

```bash
hdfs dfs -put alexandre.txt /
hdfs dfs -ls /
```

![Untitled](Datalake/Untitled%2084.png)

Acessando a interface web do Hadoop utilizando meu IP do Namenode com a porta `9870`

```bash
http://192.168.1.16:9870/
```

![Untitled](Datalake/Untitled%2085.png)

Verificando o funcionamento dos Datanodes

```bash
http://192.168.1.16:9870/dfshealth.html#tab-datanode
```

![Untitled](Datalake/Untitled%2086.png)

Verificando visualmente os arquivos dentro do HDFS

```bash
http://192.168.1.16:9870/explorer.html#/
```

![Untitled](Datalake/Untitled%2087.png)

Verifica√ß√£o do funcionamento do Yarn

```bash
http://192.168.1.16:8088/cluster
```

![Untitled](Datalake/Untitled%2088.png)

Tudo funcionando corretamente, irei desligar o Hadoop

```bash
$HADOOP_HOME/sbin/stop-all.sh
```

![Untitled](Datalake/Untitled%2089.png)



---

- Instala√ß√£o e configura√ß√£o do Apache Kafka

<aside>
üí° Para a instala√ß√£o do Kafka, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

</aside>

Primeiro passo √© fazer o Download do arquivo bin√°rio do Kafka:

[https://kafka.apache.org/downloads](https://kafka.apache.org/downloads)

![Untitled](Datalake/Untitled%2090.png)

Copie o link de download do bin√°rio:

[https://downloads.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz](https://downloads.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz)

Conectado ao Namenode, no diret√≥rio `/opt/`, fa√ßa o Download do bin√°rio

```bash
sudo wget https://downloads.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz
```

![Untitled](Datalake/Untitled%2091.png)

Ap√≥s finalizar o Download, √© necess√°rio descompact√°-lo, remover o arquivo compactado, alterar o nome e dono do arquivo.

```bash
sudo tar xzf kafka_2.13-3.3.1.tgz
sudo rm -rf kafka_2.13-3.3.1.tgz
sudo mv kafka_2.13-3.3.1/ /opt/kafka
```

![Untitled](Datalake/Untitled%2092.png)

Adotando novamente outro padr√£o, estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake kafka/
```

![Untitled](Datalake/Untitled%2093.png)

Configurando as vari√°veis de ambiente no arquivo `~/.bash_profile`

```bash
export KAFKA_HOME=/opt/kafka 
export PATH=$PATH:$KAFKA_HOME/bin
```

![Untitled](Datalake/Untitled%2094.png)

No diret√≥rio `/opt/kafka/config` fa√ßa a c√≥pia do arquivo `server.properties`

```bash
cp server.properties server1.properties
cp server.properties server2.properties
```

Agora configure os arquivos copiados.

No arquivo `server1.properties`, habilite e altere as op√ß√µes:

```bash
broker.id=1
listeners=PLAINTEXT://:9093
log.dirs=/tmp/kafka-logs-1
```

No arquivo `server2.properties`, habilite e altere as op√ß√µes:

```bash
broker.id=2
listeners=PLAINTEXT://:9094
log.dirs=/tmp/kafka-logs-2
```

Agora posso iniciar e testar o funcionamento do Kafka.

O primeiro passo para testar √© iniciar o Zookeeper pelo diret√≥rio `/opt/kafka`

```bash
bin/zookeeper-server-start.sh config/zookeeper.properties
```

![Zookeeper inicializado com sucesso!](Datalake/Untitled%2095.png)

Zookeeper inicializado com sucesso!

Abra 3 sess√µes de terminal e em cada terminal execute as configura√ß√µes feitas dos brokers.

```bash
bin/kafka-server-start.sh config/server.properties
bin/kafka-server-start.sh config/server1.properties
bin/kafka-server-start.sh config/server2.properties
```

Verifique se a porta inicializada foi a inicializada de acordo com a configura√ß√£o feita.

Inicializa√ß√£o com o arquivo `server.properties`

![Untitled](Datalake/Untitled%2096.png)

Inicializa√ß√£o com o arquivo `server1.properties`

![Untitled](Datalake/Untitled%2097.png)

Inicializa√ß√£o com o arquivo `server2.properties`

![Untitled](Datalake/Untitled%2098.png)

Abra uma nova sess√£o no terminal e crie um t√≥pico Kafka.

```bash
bin/kafka-topics.sh --create --topic BrokersTres --bootstrap-server localhost:9092 --replication-factor 3 --partitions 1
```

![Untitled](Datalake/Untitled%2099.png)

Rode o comando abaixo para descrever o status do t√≥pico criado.

```bash
bin/kafka-topics.sh --describe --topic BrokersTres --bootstrap-server localhost:9092
```

![Untitled](Datalake/Untitled%20100.png)

Inicialize o producer apontando o t√≥pico criado.

```bash
bin/kafka-console-producer.sh --topic BrokersTres --bootstrap-server localhost:9092
```

![Producer inicializado.](Datalake/Untitled%20101.png)

Producer inicializado.

Abra uma nova sess√£o no terminal e inicialize o consumer apontando o t√≥pico criado, puxando mensagens desde o in√≠cio.

```bash
bin/kafka-console-consumer.sh --topic BrokersTres --from-beginning --bootstrap-server localhost:9092
```

Escreva mensagens no producer.

![Untitled](Datalake/Untitled%20102.png)

Verifique se chegou corretamente no consumer.

![Untitled](Datalake/Untitled%20103.png)

Tudo funcionando! podemos encerrar todos os servi√ßos.

```bash
bin/zookeeper-server-stop.sh config/zookeeper.properties
bin/kafka-server-stop.sh config/server.properties
bin/kafka-server-stop.sh config/server1.properties
bin/kafka-server-stop.sh config/server2.properties
```


---

- Instala√ß√£o e configura√ß√£o do Apache Nifi

<aside>
üí° Para a instala√ß√£o do Nifi, certifique que as m√°quinas estejam com Java JDK instalado.

</aside>

A instala√ß√£o do Nifi ser√° na m√°quina local.

Primeiro passo √© fazer o Download do arquivo bin√°rio do Nifi:

![Untitled](Datalake/Untitled%20104.png)

Copie o link de download do bin√°rio:

[https://dlcdn.apache.org/nifi/1.18.0/nifi-1.18.0-bin.zip](https://dlcdn.apache.org/nifi/1.18.0/nifi-1.18.0-bin.zip)

Conectado ao Namenode, no diret√≥rio `/opt/`, fa√ßa o Download do bin√°rio

```bash
sudo wget https://dlcdn.apache.org/nifi/1.18.0/nifi-1.18.0-bin.zip
```

![Untitled](Datalake/Untitled%20105.png)

Ap√≥s finalizar o Download, √© necess√°rio descompact√°-lo, remover o arquivo compactado, alterar o nome e dono do arquivo.

```bash
sudo unzip nifi-1.18.0-bin.zip
sudo rm -rf nifi-1.18.0-bin.zip
sudo mv nifi-1.18.0/ /opt/nifi
```

Configurando as vari√°veis de ambiente no arquivo `~/.bash_profile`

```bash
export NIFI_HOME=/opt/nifi 
export PATH=$PATH:$NIFI_HOME/bin
```

Iniciando o Apache Nifi

<aside>
üí° S√≥ ir√° rodar se voc√™ tiver o Java instalado em sua m√°quina local.

</aside>

```bash
$NIFI_HOME/bin/nifi.sh start
```

![Untitled](Datalake/Untitled%20106.png)

Crie um usu√°rio no Nifi

```bash
$NIFI_HOME/bin/nifi.sh set-single-user-credentials <usuario> <senha>
```

Acesse

```bash
https://localhost:8443/nifi/login
```

Utilize o login criado.

![Untitled](Datalake/Untitled%20107.png)

![Untitled](Datalake/Untitled%20108.png)

Desligue o Nifi

```bash
$NIFI_HOME/bin/nifi.sh stop
```

Instala√ß√£o do Nifi conclu√≠da.


---

- Instala√ß√£o e configura√ß√£o do Apache Spark

<aside>
üí° Para a instala√ß√£o do Spark, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

</aside>

Primeiro passo √© fazer o Download do arquivo bin√°rio do Spark:

[https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html)

![Untitled](Datalake/Untitled%20109.png)

Copie o link de Download do bin√°rio:

[https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz](https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz)

![Untitled](Datalake/Untitled%20110.png)

Abra o terminal do Namenode, v√° ao diret√≥rio `/opt/` e insira o comando `wget` com o link bin√°rio do Spark:

<aside>
üí° S√≥ ser√° poss√≠vel a execu√ß√£o do comando `wget`, caso voc√™ tenha ele instalado.

</aside>

```bash
sudo wget https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz
```

![Untitled](Datalake/Untitled%20111.png)

Verificando, extraindo, removendo o arquivo compactado e alterando o nome do diret√≥rio.

```bash
ls -la
sudo tar xzf spark-3.3.1-bin-hadoop3.tgz
sudo rm -rf spark-3.3.1-bin-hadoop3.tgz
sudo mv spark-3.3.1-bin-hadoop3/ /opt/spark
```

![Untitled](Datalake/Untitled%20112.png)

Adotando novamente outro padr√£o, estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake spark/
```

![Untitled](Datalake/Untitled%20113.png)

Agora irei configurar as vari√°veis de ambiente do meu usu√°rio datalake inserindo as seguintes configura√ß√µes:

```bash
export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin
```

![Untitled](Datalake/Untitled%20114.png)

Testando seu funcionamento.

```bash
spark-shell
```

![Untitled](Datalake/Untitled%20115.png)

Utilize o atalho `CTRL+C` para fechar o `spark-shell`

- **Configurando o Spark em Multinode Cluster**

Entre no diret√≥rio `/opt/spark/conf` e fa√ßa uma c√≥pia renomeada sem .template dos arquivos `spark-env.sh.template` e `workers.template`

```bash
cp spark-env.sh.template spark-env.sh
cp workers.template workers
```

Edite o arquivo `workers` e insira o IP dos Datanodes:

![Untitled](Datalake/Untitled%20116.png)

Edite o arquivo `spark-env.sh` e insira

```bash
export SPARK_MASTER_HOST=namenode
export JAVA_HOME=/opt/jdk
```

![Untitled](Datalake/Untitled%20117.png)

Para iniciar o Spark √© necess√°rio primeiro instalar-lo tamb√©m nas outras m√°quinas, estarei fazendo a c√≥pia do Namenode para os Datanodes.

Primeiramente √© necess√°rio criar o diret√≥rio do Spark nos Datanodes e alterar o dono do diret√≥rio.

```bash
sudo mkdir /opt/spark
sudo chown -R datalake:datalake /opt/spark/
```

![Untitled](Datalake/Untitled%20118.png)

Fa√ßa a c√≥pia do Namenode para os Datanodes.

```bash
scp -rv -i "~/.ssh/id_rsa" /opt/spark datalake@datanode1:/opt
scp -rv -i "~/.ssh/id_rsa" /opt/spark datalake@datanode2:/opt
```

Verifique se chegou corretamente nos Datanodes.

![Untitled](Datalake/Untitled%20119.png)

Agora podemos rodar o Multinode pelo Namenode

```bash
$SPARK_HOME/sbin/start-all.sh
```

![Untitled](Datalake/Untitled%20120.png)

Verificando em todas as m√°quinas se os servi√ßos foram iniciados corretamente

```bash
jps
```

Namenode

![Untitled](Datalake/Untitled%20121.png)

Datanode1

![Untitled](Datalake/Untitled%20122.png)

Datanode2

![Untitled](Datalake/Untitled%20123.png)

Inicie o `spark-shell`

```bash
spark-shell --master spark://namenode:7077
```

![Untitled](Datalake/Untitled%20124.png)

Utilize o atalho `CTRL+C` para fechar o `spark-shell`

Verifique se todos os Datanodes est√£o sincronizados.

```bash
http://192.168.1.9:4040
```

![Untitled](Datalake/Untitled%20125.png)

Tamb√©m √© poss√≠vel verificar atrav√©s do endere√ßo:

```bash
http://192.168.1.9:8080/
```

![Untitled](Datalake/Untitled%20126.png)

Parando todos os servi√ßos

```bash
$SPARK_HOME/sbin/stop-all.sh
```

Instala√ß√£o do Spark conclu√≠da.



---

- Instala√ß√£o e configura√ß√£o do Apache Hive

<aside>
üí° Para a instala√ß√£o do Hive, certifique que todas as m√°quinas estejam iniciadas e com o Java JDK instalado.

</aside>

Primeiro passo √© fazer o Download do arquivo bin√°rio do Hive:

[https://dlcdn.apache.org/hive/](https://dlcdn.apache.org/hive/)

![Untitled](Datalake/Untitled%20127.png)

Escolha a vers√£o e copie o link de Download do bin√°rio:

[https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz](https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz)

![Untitled](Datalake/Untitled%20128.png)

Abra o terminal do Namenode, v√° ao diret√≥rio `/opt/` e insira o comando `wget` com o link bin√°rio do Hive:

<aside>
üí° S√≥ ser√° poss√≠vel a execu√ß√£o do comando `wget`, caso voc√™ tenha ele instalado.

</aside>

```bash
sudo wget https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz
```

![Untitled](Datalake/Untitled%20129.png)

Verificando, extraindo, removendo o arquivo compactado e alterando o nome do diret√≥rio.

```bash
ls -la
sudo tar xzf apache-hive-3.1.3-bin.tar.gz 
sudo rm -rf apache-hive-3.1.3-bin.tar.gz 
sudo mv apache-hive-3.1.3-bin/ /opt/hive
```

![Untitled](Datalake/Untitled%20130.png)

Estarei colocando no usu√°rio datalake todas as instala√ß√µes dos componentes Apache.

```bash
sudo chown -R datalake:datalake hive/
```

![Untitled](Datalake/Untitled%20131.png)

Exportando as vari√°veis de ambiente:

```bash
export HIVE_HOME=/opt/hive
export PATH=$PATH:$HIVE_HOME/bin
```

![Untitled](Datalake/Untitled%20132.png)

Verifique a vers√£o do Hive

```bash
hive --version
```

![Untitled](Datalake/Untitled%20133.png)

Antes de inicializar √© necess√°rio ter um banco de dados relacional para armazenar o Metastore do Hive.

- **Configura√ß√£o do Metastore com Banco de Dados Oracle**

√â necess√°rio o Download do conector JDBC do Oracle.

[https://www.oracle.com/br/database/technologies/appdev/jdbc-downloads.html](https://www.oracle.com/br/database/technologies/appdev/jdbc-downloads.html)

![Untitled](Datalake/Untitled%20134.png)

Copie o link e fa√ßa o Download no diret√≥rio `/opt/hive/lib/`

```bash
sudo wget https://download.oracle.com/otn-pub/otn_software/jdbc/217/ojdbc8.jar
```

![Untitled](Datalake/Untitled%20135.png)

Altere o dono e grupo do arquivo para datalake

```bash
sudo chown -R datalake:datalake ojdbc8.jar
```

Antes de qualquer passo √© necess√°rio iniciar o HDFS.

```bash
$HADOOP_HOME/sbin/start-dfs.sh
```

![Untitled](Datalake/Untitled%20136.png)

Iniciando o banco de dados Oracle

![Untitled](Datalake/Untitled%20137.png)

Utilizarei o SQL Developer para se conectar ao Oracle

Se conectando ao usu√°rio sys

![Untitled](Datalake/Untitled%20138.png)

Criando um usu√°rio no banco de dados e dando privil√©gios:

![Untitled](Datalake/Untitled%20139.png)

Testando a conex√£o

![Untitled](Datalake/Untitled%20140.png)

Agora rode o script que √© disponibilizado pelo Hive no diret√≥rio 

```bash
/opt/hive/scripts/metastore/upgrade/oracle
```

Copie o conte√∫do dentro do arquivo `hive-schema-3.1.0.oracle.sql` e rode no SQL Developer.

![Untitled](Datalake/Untitled%20141.png)

Agora √© necess√°rio configurar o Hive para se conectar com o banco Oracle

No diret√≥rio `/opt/hive/conf` crie o arquivo `hive-site.xml`

```bash
vi hive-site.xml
```

Dentro do arquivo insira as configura√ß√µes.

```html
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:oracle:thin:@//192.168.1.11/ORCL12C</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>oracle.jdbc.OracleDriver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
    </property>
</configuration>
```

![Untitled](Datalake/Untitled%20142.png)

Rode o comando para criar o schema:

<aside>
üí° Para funcionar corretamente √© necess√°rio configurar o arquivo `tnsnames.ora` do banco de dados Oracle.

</aside>

```bash
/opt/hive/bin/schematool -dbType oracle -initSchema
```

Agora √© s√≥ rodar o comando Hive.

<aside>
üí° O comando `hive` s√≥ vai funcionar se as vari√°veis de ambiente estiverem configuradas corretamente.

</aside>

![Untitled](Datalake/Untitled%20143.png)

Instala√ß√£o conclu√≠da.

- **Configura√ß√£o do Metastore com Banco de Dados MySQL**

Baixar o conector JDBC do MySQL

[https://dev.mysql.com/downloads/connector/j/](https://dev.mysql.com/downloads/connector/j/)

![Untitled](Datalake/Untitled%20144.png)

Utilize o comando wget para baixar no diret√≥rio `/opt/hive/lib`

```bash
sudo wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-j-8.0.31.zip
```

![Untitled](Datalake/Untitled%20145.png)

Ap√≥s baixar √© hora de extrair

```bash
sudo unzip mysql-connector-j-8.0.31.zip
```

![Untitled](Datalake/Untitled%20146.png)

Removendo o arquivo baixado.

```bash
sudo rm -rf mysql-connector-j-8.0.31.zip
```

Entre no diret√≥rio `mysql-connector-j-8.0.31`

```bash
cd /opt/hive/lib/mysql-connector-j-8.0.31
```

Mova o `mysql-connector-j-8.0.31.jar` para o `/opt/hive/lib/`

```bash
sudo mv mysql-connector-j-8.0.31.jar /opt/hive/lib
```

Altere o dono e grupo do arquivo `mysql-connector-j-8.0.31.jar` 

```bash
sudo chown -R datalake:datalake mysql-connector-j-8.0.31.jar
```

Agora crie um banco de dados no MySQL

Inicie o MySQL

```bash
mysql -u root -p
```

![Untitled](Datalake/Untitled%20147.png)

```sql
CREATE DATABASE METASTORE;
```

![Untitled](Datalake/Untitled%20148.png)

Entre no banco criado.

```sql
USE METASTORE;
```

![Untitled](Datalake/Untitled%20149.png)

Agora crie o schema do Hive

```sql
source /opt/hive/scripts/metastore/upgrade/mysql/hive-schema-3.1.0.mysql.sql
```

![Untitled](Datalake/Untitled%20150.png)

Cria√ß√£o de um usu√°rio para a conex√£o do Hive.

```sql
CREATE USER 'hive' IDENTIFIED BY 'eYsfh$99N6';
```

![Untitled](Datalake/Untitled%20151.png)

Concess√£o de privil√©gios para o usu√°rio `hive`

```sql
GRANT ALL PRIVILEGES ON *.* TO hive;
flush privileges;
```

![Untitled](Datalake/Untitled%20152.png)

Agora √© hora de configurar o Hive .

Entre no diret√≥rio `/opt/hive/conf`,crie o arquivo `hive-site.xml` e insira as configura√ß√µes.

```html
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>eYsfh$99N6</value>
    </property>
</configuration>
```

Tudo configurado, agora podemos rodar o Hive, para isso √© necess√°rio antes rodar o HDFS e o Yarn.

```bash
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/yarn-dfs.sh
```

![Untitled](Datalake/Untitled%20153.png)

Antes de rodar o hive √© necess√°rio tirar o HDFS do modo Safe:

```bash
hdfs dfsadmin -safemode leave
```

Rode o comando para iniciar o schema criado no MySQL.

```bash
schematool -dbType mysql -initSchema
```

![Untitled](Datalake/Untitled%20154.png)

Agora rodamos o comando `Hive`

![Untitled](Datalake/Untitled%20155.png)

Conclu√≠do a instala√ß√£o!


- **Testando o Hive**

Para testar o Hive primeiramente irei criar uma tabela nele.

```sql
CREATE TABLE datalake (COL1 INT);
```

![Untitled](Datalake/Untitled%20156.png)

Verificando o Metastore pelo banco de dados MySQL. 

```sql
USE METASTORE;
SELECT * FROM TBLS;
```

![Untitled](Datalake/Untitled%20157.png)

Metastore da tabela Hive (Datalake) criada com sucesso!

Para esse teste vou incluir arquivos `.csv` no meu HDFS. Estarei utilizando como base um arquivo `.csv` da minha autoria e o repartir em 3 arquivos.

![Untitled](Datalake/Untitled%20158.png)

Criando a pasta cliente e movendo os arquivos `.csv` para dentro dela.

```bash
hdfs dfs -mkdir /cliente
hdfs dfs -mv /cliente1.csv /cliente
hdfs dfs -mv /cliente2.csv /cliente
hdfs dfs -mv /cliente3.csv /cliente
hdfs dfs -ls /cliente
```

![Untitled](Datalake/Untitled%20159.png)

Estruturando arquivos `.csv` para rodar no Hive.

```sql
CREATE EXTERNAL TABLE Cliente (
CPF STRING,
NOME STRING,
SOBRENOME STRING,
DATA_NASCIMENTO STRING,
ID_ENDERECO STRING,
EMAIL STRING,
CONTATO STRING,
SALARIO STRING,
DATA_INICIO STRING,
DATA_FIM STRING,
ID_FUNCIONARIO STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
location '/cliente/';
```

![Untitled](Datalake/Untitled%20160.png)

Executando uma query

```sql
SELECT * FROM CLIENTE;
```

![Untitled](Datalake/Untitled%20161.png)

Conclu√≠do o teste com o Hive!

Ap√≥s todas essas instala√ß√µes, o Data Lake est√° pronto para uso.<br/>

Link para o download das 3 VMS com todas as m√°quinas j√° configuradas:<br/>

[Namenode](https://drive.google.com/file/d/1enoBERjVq_4dFeLTIPZSEqgfKMfOQ9Q3/view?usp=share_link)<br/>

[Datanode1](https://drive.google.com/file/d/1et9ZYkjXO4cPS9nmG_b2cW1EaQ9QSrWm/view?usp=share_link)<br/>

[Datanode2](https://drive.google.com/file/d/1hJqkCXUM7ZMRxHm5SZXHW_p9A_KYRCpD/view?usp=share_link)<br/>

---

